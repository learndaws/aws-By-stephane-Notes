Three main deployment models of cloud:

* Private Cloud
* Public Cloud
* Hybrid Cloud

------------------------------------------------------------------------------------------------------

Five characteristics of Cloud computing:

* On-demand Selfservice
* Broad Network Access 
* Multi-tenancy and resource pooling
* Rapid elasticity and scalability
* Measured units

------------------------------------------------------------------------------------------------------

Six advantages of cloud computing:

* Trade capital expense(CAPEX) over operational expence(OPEX) 
* Benefit from massive economies of scale
* stop guessing capacity
* Increase speed and agility
* Stop spending money running and maintaining the datacenters
* Go global in minutes: leverage the AWS global infrastructure

------------------------------------------------------------------------------------------------------

Four different types of cloud computing:

* infrastructure as a Service (Iaas) 
          Example from AWS : Ec2 instance
        Example from Others: Azure, GCP, Rackspace, Digital Ocean, Linode

* Platform as a Service (PaaS) 
          Example from AWS : Elastic Beanstalk
        Example from Others: Heroku, Google App Engine(GCP), Windows Azure(Microsoft)

* Software as a Service (SaaS)
          Example from AWS : Many like Rekognition for Meachine Learning
        Example from Others: Google Apps(Gmail), Dropbox, Zoom

* Function as a Service (Faas)
          Example from AWS : Lambda
        Example from Others: "Need to update"

* Container as a Service (CaaS)
          Example from AWS : Amazon Elastic Container Service (ECS), Fargate
        Example from Others: Google Kubernetes Engine (GKE), Azure Kubernetes Service (AKS)     

* Infrastructure as a Code (IaC)
          Example from AWS : CloudFormation
        Example from Others: "Need to update"  

------------------------------------------------------------------------------------------------------

Three pricing fundamentals of Cloud (Pay-as-you-go):

* Computing - Pay for compute time
* Storage - Pay for on the amount of data stored
* Netowrking - Pay only for amount of outgoing traffic i.e., from cloud.. Amount of Incoming traffic data is free

------------------------------------------------------------------------------------------------------

How to choose the region for Application deployment:

* Based on Compliance with data governance and legal requirements
* Proximity to customers: Reduced latency
* Service availability in a choosen region
* Pricing of the region

------------------------------------------------------------------------------------------------------

Four MFA device options in AWS:

* Virtual MFA device 
        Example: Google Authenticator from Google
                 Authy from AWS 
                
* Universal 2nd Factor(U2F) Security Key
        Example: Yubikey from Yubico (Yubico is 3rd party to Amazon)

* Hardware Key Fob MFA device
        Example: It's from Gemalto (3rd party)

* Hardware Key Fob MFA device for AWS GovCloud (US)
        Example: It's from SurePassID (3rd party)

------------------------------------------------------------------------------------------------------

Three ways users can access AWS:

* AWS Management console (Password + MFA)
* AWS CLI (Protected by Access and secret Keys)
* AWS Software Development Kit (SDK) (For Code: Protected by Access and secret Keys)

------------------------------------------------------------------------------------------------------

Two IAM Security Tools:

* IAM Credentials Report (Account-level)
        --> A report that lists all your account's users and the status of their various credentials.

* IAM Access Advisor (User-level)
        --> It shows the service permissions granted to the user and when those services were last used.

------------------------------------------------------------------------------------------------------

EC2 mainly consists in the capability of following:

* Renting virtual machines (EC2)
* Storing data on virtual drives (EBS)
* Distributing load across machines (ELB)
* Scaling services using an auto-scaling group (ASG)

------------------------------------------------------------------------------------------------------

Seven types of EC2 Instances:

* General Purpose
        --> Great for a diversity of workloads such as webservers or code repositories.
        --> These are great balance between Compute, Memory and Networking.

* Compute Optimized
        -> Great for compute intensive tasks which requires high performance processors such as below.
                # Batch processing workloads
                # Media transcoding
                # High performance webservers
                # High performance computing
                # Scientific modeling and machine learning
                # Dedicated gaming servers

* Memory Optimized
        -> Great for fast performance for workloads that process large sets of memory. 
        -> Following are use cases
                # High performance, Relational/Non-Relational databses
                # Distributed web scale cache stores
                # In-memory databases optimized for BI (Business Intelligence)
                # Applications performing real-time processing of big unstructured data

* Storage Optimized
        -> Great for storage intensive tasks that require high, sequential read and write to large data sets on local      storage.
        -> Following are use cases
                # High frequesncy online transaction processing (OLTP) systems.
                # Relational and NoSQL databases
                # Cache for In-memory databases (Ex: Redis)
                # Data warehousing applications
                # Distributing file systems

------------------------------------------------------------------------------------------------------

EBS snapshot Features:

1) EBS Snapshot Archive
        * Move a snapshot to an "archive tier" that is 75% cheaper 
        * It takes 24hrs to 72hrs to restore from archive

2) Recycle bin for EBS Snapshots
        * Setup rules to retain deleted snapshops so you can recover them after an accidental deletion.
        * Specify retention (from 1 day to 1 year)

------------------------------------------------------------------------------------------------------

Amazon S3 usecases:

1) Backup and Storage
2) Disaster Recovery
3) Archive
4) Hybrid Cloud Storage
5) Application hosting
6) Media hosting
7) Data lakes and Big data analysis
8) Software delivery
9) Static website

------------------------------------------------------------------------------------------------------

S3 Storage Classes:

1) Amazone S3 Standard - General Purpose
        * 99.99% Availability
        * used for frequently accessed data
        * low latency and high throughput
        * sustain 2 concurrent facility failures
        * Use Cases: Big Data Analytics, Mobile and Gaming Applications, Content distribution..

2) Infrequent Access (IA)
        * Data that is less frequently access, but requires rapid access when needed
        * Lower cost than general purpose, but cost application on retrieval

                2A) Amazone S3 Standard-Infrequent Access (IA):        
                        * 99.9% Availability
                        * Use Cases: Disaster Recovery, Backups

                2B) Amazon S3 One Zone-Infrequent Access:
                        * High durability(99.999999999) in a single AZ, but lost when AZ is destroyed
                        * 99.5% Availability
                        * Use Cases: Storing secondary backup copies on-premise data, or data you can recreate
   
3) Glacier
        * Low cost object storage meant for archiving/backup
        * Pricing: price for storage + object retrieval cost

                3A) Amazon S3 Glacier Instance Retrieval:
                        * Millisecond retieval, great for data accessed once a quarter
                        * Minimum storage duration of 90 days

                3B) Amazon S3 Glacier Flexible Retrieval:
                        * Expedited (1 to 5 minutes), Standard (3 to 5 hours), Bulk (5 to 12 hours) - free
                        * Minimum storage duration of 90 days
                        
                3C) Amazon S3 Deep Archive - for longterm storage: 
                        * Standard (12 hours), Bulk (48 hours)
                        * Minimum storage duration of 180 days

4) Amazon S3 Intelligent Tiering
        * Small monthly monitoring and auto-tiering fee
        * Moves objects automatically between access tiers based on usage
        * There are no retrieval charges 

                4A) Frequent Access tier (automatic): default tier
                4B) Infrequent Access tier (automatic): object not accessed for 30 days
                4C) Archive Instant Access tier (automatic): object not accessed for 90 days
                4D) Archive Access tier (optinoal): configurable from 90 days to 700+ days
                4E) Deep Archive Access tier (optinoal):   configurable from 180 days to 700+ days
                
------------------------------------------------------------------------------------------------------

AWS Snow Family:

* Highly-secure, portable devices to collect and process data at the edge, and migrate data in and out of AWS
* Use-cases:
        a) Data Migration
                - Snowball Edge
                        * Physical data transport solution: TBs or PBs in or out of AWS
                        * Alternative to moving data over network
                        * pay per data trnasfer job
                        * provide block storage and Amazon S3-compatible object storage
                        * Snowball Edge storage optimized(80TB of HDD or 210TB NVMe capacity for block volume and S3    compatible object storge)
                        * Snowball Edge compute optimized(42TB of HDD or 28TB NVMe capacity for block volume and S3 compatible object storge)
                        * Use cases: large data cloud migrations, DC decommission, disaster recovery
                - Snowcone
                        * Small, portable computing, anywhere, rugged & secure, withstands harsh environments
                        * Light (2.1Kg)
                        * Device used for Edge computing, storage and data transfer
                        * Snowcone - 8TB of HDD Storage
                        * Snowcone SSD - 14TB SSD Storage
                        * Use Snowcone where Snowball doesn't fit(Space-constrained environment)
                        * Must provide your own battery/cables
                        * Can be sent back to AWS offline, or connect it to internet and use AWS DataSync to send data.
                - Snowmobile 
                        * They send us a big truck
                        * Transfer exabytes of date (1EB = 1000PB = 1,000,000TBs)
                        * Each snowmobile has 100PB of capacity (use multiple in parallel)
                        * High security: temperature controlled, GPS, 24/7 video surveillance
                        * Better than snowball if you transfer more than 10PB

        b) Edge Computing (locations or anyother which doesn't have internet access)
                - Snowball Edge
                - Snowcone

------------------------------------------------------------------------------------------------------

AWS Storage Gateway:

* Bridge between on-premise data storage and cloud data storage in S3
* Hybrid storage service to allow on-premises to seamlessly use the AWS cloud
* Use Cases: disaster recovery, backup and restore, tiered storage

------------------------------------------------------------------------------------------------------

Databases and Analystics Summary in AWS:

* Relational Databases - OLTP: RDS & Aurora (SQL)
* In-memory Database: Elastic Cache
* Key/Value Database: DynamoDB (Serverless) & DAX (Cache for DynamoDB)
* Warehouse - OLAP (Redshift) (SQL)
* Hadoop cluster - EMR
* Athena: Query data on Amazon S3 (Serverless & SQL)
* Qucksight: dashboards on your data (Serverless)
* DocumentDB: "Aurora for MongoDB" (JSON - NoSQL Database)
* Amazon QLDB: Financial Transactions Ledger (immutable journal, cryptographically verifiable)
* Amazon Managed Blockchain: Managed Hyperledger Fabric & Ethereum Blockchains
* Glue: Managed ETL (Extract Transform Load) and Data Catalogue Service
* Database Migration: DMS
* Neptune: Graph Database
* Timestream: Time-series database

   -> SQL Databases: RDS, Aurora, Redshift, Athena
   -> NoSQL Databases: DynamoDB, DocumentDB
   -> Serverless: DynamoDB, Athena, Qucksight  (Someother: Amazon S3, Fargate, Lambda, Cloudwatch, API Gateway, AWS Code Build, Amazon SQS)

* RDS Multi-AZ deployments’ main purpose is high availability
* RDS Read replicas’ main purpose is scalability
* Multi-Region deployments’ main purpose is disaster recovery and local performance.

------------------------------------------------------------------------------------------------------

Amazon Ec2 instance Vs Lambda:

* Ec2 Instance
  ------------
        - We have an virtual server in the cloud
        - Limited by RAM and CPU
        - Continously running
        - Scaling means intervention to add/remove servers

* Lambda
  ------
        - Virtual funtions - No servers to manage
        - Limited by time - short executions
        - Run on-demand
        - Scaling is automated!

------------------------------------------------------------------------------------------------------

AWS Batch Vs Lambda:

* AWS Batch
  ------------
        - No Time limit
        - Any runtime as long as it's packaged as a docker image
        - Relies on EBS/Instance Store for disk space
        - It's not a serverless 

* Lambda
  ------
        - Time limit
        - Limited runtimes
        - Limited temporary disk space
        - Serverless

------------------------------------------------------------------------------------------------------

Global Applications in AWS:

* Global DNS: Route53
        - Great to route users to the closest deployment with least latency
        - Great for disaster recovery strategies

* Global Content Delivery Network(CDN): CloudFront
        - Replicate part of your application to AWS Edge locations - decrease latency
        - Cache common requests - improved user experience and decreased latency

* S3 Transfer Acceleration
        - Accelerate global uploads and downloads into Amazon S3

* AWS Global Accelerator
        - Improve global application availability and performance using the AWS Global Network

------------------------------------------------------------------------------------------------------

Application de-coupling Services:

* SQS (Simple Queueing Service) --> Cloud Native
        - Producer send message to SQS and consumer reads it and delete it.
        - Multiple producers can send the messages and read by multiple consumers.
        - Let say producer-A sends message and consumer-1 reading it and during this process which means before deletion of message by consumer-1, consumer-2 can be able able to read it but if consumer-1 reads and deletes the messages and now consumer-2 will not be able to read the message.
        - Default retention of message-4 days, and maximum-14days.

* SNS (Simple Notification Service) --> Cloud Native
        - SNS is a pub/sub (publish/subscribe) messaging system.
        - It allows you to send messages to multiple subscribers (e.g., email, HTTP endpoints, SQS queues).
        - Messages are immediately sent to all subscribers once they are published.
        - It supports multiple protocols, such as HTTP/HTTPS, email, SMS, and SQS.
        - Messages are not stored; they are sent to subscribers immediately and not retained.
        - Single message sent by publisher to SNS topic, it will be immediately delivered to all the subscribers who are in subscriber list.

* Kinesis--> Cloud Native
        - It's a real-time big data streaming
        - Managed service to collect, process, and analyze real-time streaming data at any scale

* Amazon MQ--> Cloud Native
        - Traditional applications running from on-premises may use open protocols such as: MQTT, AMQP, STOMP, Openwire, WSS
        - When migrating to cloud instead of re-engineering the application to use SQS and SNS, we caan use Amazon MQ
        - Amazon MQ is a managed message broker serice for "Rabbit MQ" and "Active MQ"
        - Amazon MQ doesn't scale as much as SQS/SNS
        - Amazon MQ run on Server, can run in Multi-AZ with failover
        - Amazon MQ has both queue feature (~SQS) and topic feature (~SNS)


Note: Need to learn S3 Storage Snow family.